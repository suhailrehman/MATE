{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XASH Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "import math\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XASH(token: str, hash_size: int = 128) -> int:\n",
    "    \"\"\"Computes XASH for given token.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    token : str\n",
    "        Token.\n",
    "\n",
    "    hash_size : int\n",
    "        Number of bits.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        XASH value.\n",
    "    \"\"\"\n",
    "    number_of_ones = 5\n",
    "    char = [' ', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i',\n",
    "            'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "    segment_size_dict = {64: 1, 128: 3, 256: 6, 512: 13}\n",
    "    segment_size = segment_size_dict[hash_size]\n",
    "    length_bit_start = 37 * segment_size\n",
    "    result = 0\n",
    "    cnt_dict = Counter(token)\n",
    "    selected_chars = [y[0] for y in sorted(cnt_dict.items(), key=lambda x: (x[1], x[0]), reverse=False)[:number_of_ones]]\n",
    "    for c in selected_chars:\n",
    "        if c not in char:\n",
    "            continue\n",
    "        indices = [i for i, ltr in enumerate(token) if ltr == c]\n",
    "        mean_index = np.mean(indices)\n",
    "        token_size = len(token)\n",
    "        for i in np.arange(segment_size):\n",
    "            if mean_index <= ((i + 1) * token_size / segment_size):\n",
    "                location = char.index(c) * segment_size + i\n",
    "                break\n",
    "        result = result | int(math.pow(2, location))\n",
    "\n",
    "    # rotation\n",
    "    n = int(result)\n",
    "    d = int((length_bit_start * (len(token) % (hash_size - length_bit_start))) / (\n",
    "                hash_size - length_bit_start))\n",
    "    int_bits = int(length_bit_start)\n",
    "    x = n << d\n",
    "    y = n >> (int_bits - d)\n",
    "    r = int(math.pow(2, int_bits))\n",
    "    result = int((x | y) % r)\n",
    "\n",
    "    result = int(result) | int(math.pow(2, len(token) % (hash_size - length_bit_start)) * math.pow(2, length_bit_start))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sample dataframe list\n",
    "\n",
    "df_sample_list = '/tank/local/suhail/data/relic-datalake/gittables/samples/5000_sample.txt'\n",
    "\n",
    "with open(df_sample_list, 'r') as fp:\n",
    "    file_list = [eval(x) for x in fp.readlines()]\n",
    "            \n",
    "sample_df = pd.read_parquet(file_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row = sample_df.iloc[0]\n",
    "sample_row.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sample_row.iteritems())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def generate_hash_superkey(row, hash_function=XASH, hash_size=128):\n",
    "    superkey = 0\n",
    "    value_list = []\n",
    "    for colname, val in row.iteritems():\n",
    "        value = str(val)\n",
    "        superkey = superkey | hash_function(value, hash_size)\n",
    "        value_list.append((colname, value))\n",
    "    return superkey, value_list\n",
    "\n",
    "def index_dataframe(df):\n",
    "    for idx, row in df.iterrows():\n",
    "        superkey, value_list = generate_hash_superkey(row)\n",
    "        yield idx, superkey, value_list\n",
    "        \n",
    "        \n",
    "def generate_posting_list(df, label='label'):\n",
    "    posting_list = defaultdict(list)\n",
    "    for idx, superkey, value_list in index_dataframe(df):\n",
    "        for colname, value in value_list:\n",
    "            posting_list[value].append((label, idx, colname, superkey))\n",
    "    return posting_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_hash_superkey(sample_row, XASH, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_posting_list(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrow Server Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.arrow_client import *\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = FlightSketchClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.constuct_index_df(pa.table(sample_df), 'sample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.serialize_sketches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Querying Prototyping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "server_serialized_file = \"MATE/src/sketchset.ser\"\n",
    "\n",
    "with open(server_serialized_file, 'rb') as fp:\n",
    "    posting_list, table_pl = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_pl.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load query dataframe\n",
    "query_output_dir='/tank/local/suhail/data/relic-datalake/gittables/outputs/100_queries/artifacts/'\n",
    "query_ops_file='/tank/local/suhail/data/relic-datalake/gittables/outputs/100_queries/operations.parquet'\n",
    "\n",
    "query_df = pd.read_parquet(query_ops_file)\n",
    "query_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_queries = query_df.loc[(query_df.operation == 'groupby') & (query_df.colset_size == 2)]\n",
    "gb_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_query_df = pd.read_parquet(gb_queries.iloc[0]['dst_label'])\n",
    "query_cols = gb_queries.iloc[0]['args']['colset']\n",
    "query_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_df = sample_query_df[query_cols]\n",
    "q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ICS(query_df):\n",
    "    all_cardinalities = query_df.apply(lambda x: x.nunique())\n",
    "    return all_cardinalities.idxmin()\n",
    "\n",
    "\n",
    "def initial_pl_filter(query_df, posting_list):\n",
    "    init_column = perform_ICS(query_df)\n",
    "    init_values = set(query_df[init_column])\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "perform_ICS(q_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def generate_hash_superkey(row, hash_function=XASH, hash_size=128):\n",
    "    superkey = 0\n",
    "    value_list = []\n",
    "    for colname, val in row.iteritems():\n",
    "        value = str(val)\n",
    "        superkey = superkey | hash_function(value, hash_size)\n",
    "        value_list.append((colname, value))\n",
    "    return superkey, value_list\n",
    "\n",
    "def perform_initial_table_filtering(q_df, posting_list):\n",
    "    init_column = perform_ICS(q_df)\n",
    "    init_values = set(q_df[init_column].values.astype(str))\n",
    "\n",
    "    initial_table_list = defaultdict(list)\n",
    "    for value in init_values:\n",
    "        for tableid, rowid, colid, superkey in posting_list[value]:\n",
    "            initial_table_list[tableid].append((value, rowid, colid, superkey))\n",
    "            \n",
    "    return sorted(initial_table_list.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "\n",
    "def perform_row_filtering(q_df, posting_list, table_pl, initial_table_list, superkeydf, init_col_label):\n",
    "    ranked_table_list = []\n",
    "    for tableid, table_pls in initial_table_list:\n",
    "        # TODO: Early stopping condition\n",
    "        matching_rows = []\n",
    "        for value, rowid, colid, superkey in table_pls:\n",
    "            # Get list of unqiue superkeys for the value in the query table\n",
    "            # TODO: Second early stopping condition based on num_rows checked\n",
    "            init_row_match = superkeydf.loc[superkeydf[init_col_label] == value]\n",
    "            for idx, sk_row in init_row_match.iterrows():\n",
    "                if sk_row['superkey'] | superkey == superkey:\n",
    "                     matching_rows.append((tableid, rowid, colid, value))\n",
    "            \n",
    "        ranked_table_list.append((tableid, matching_rows))\n",
    "    \n",
    "    return sorted(ranked_table_list, key=lambda x: len(x[1]), reverse=True)\n",
    "    \n",
    "\n",
    "    \n",
    "def get_query_superkey(q_df, hash_function=XASH, hash_size=128):\n",
    "    q_sk_df = q_df.copy()\n",
    "    q_sk_df['superkey'] = q_sk_df.apply(lambda x: generate_hash_superkey(x, hash_function, hash_size)[0], axis=1)\n",
    "    return q_sk_df\n",
    "\n",
    "\n",
    "def process_gb_query(gb_query, posting_list, table_pl):\n",
    "    q_df = pd.read_parquet(gb_query['dst_label'])[gb_query['args']['colset']]\n",
    "    superkeydf = get_query_superkey(q_df)\n",
    "    init_table_list = perform_initial_table_filtering(q_df, posting_list)\n",
    "    final_ranked_list = perform_row_filtering(q_df, posting_list, table_pl, init_table_list, superkeydf, perform_ICS(q_df))\n",
    "    return [x[0] for x in final_ranked_list]\n",
    "\n",
    "\n",
    "gb_results = gb_queries.copy()\n",
    "\n",
    "#gb_results['results'] = gb_results.apply(lambda x: process_gb_query(x, posting_list, table_pl), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test One Query\n",
    "gb_query = gb_results.iloc[2]\n",
    "q_df = pd.read_parquet(gb_query['dst_label'])[gb_query['args']['colset']]\n",
    "superkeydf = get_query_superkey(q_df)\n",
    "init_table_list = perform_initial_table_filtering(q_df, posting_list)\n",
    "#final_ranked_list = perform_row_filtering(q_df, posting_list, table_pl, init_table_list, superkeydf, perform_ICS(q_df))\n",
    "init_table_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ranked_list = perform_row_filtering(q_df, posting_list, table_pl, init_table_list, superkeydf, perform_ICS(q_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(init_table_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_df#.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_queries.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_results.to_parquet('gb_results.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_results['src_filename'] = gb_results['src_labels'].apply(lambda x: os.path.basename(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_groupby_result_in_k(row, k=10):\n",
    "    correct_src = row['src_filename']\n",
    "    found_correct_src = -1\n",
    "    ranked_results = 0\n",
    "    total_results = 0\n",
    "    \n",
    "    try:\n",
    "        total_results = len(row['results'])\n",
    "        \n",
    "        for ix, rank_item in enumerate(row['results']):\n",
    "            if rank_item == correct_src and found_correct_src == -1:\n",
    "                found_correct_src = ranked_results\n",
    "            ranked_results += 1\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "            \n",
    "    return pd.Series([found_correct_src, ranked_results, total_results])\n",
    "\n",
    "def verify_pivot_result_in_k(row, k=10):\n",
    "    correct_src = row['src_filename']\n",
    "    found_correct_src = -1\n",
    "    ranked_results = 0\n",
    "    total_results = len(row['results'])\n",
    "    \n",
    "    for ix, rank_item in enumerate(row['results']):\n",
    "        if rank_item == correct_src  and found_correct_src == -1:\n",
    "            found_correct_src = ranked_results\n",
    "        ranked_results += 1\n",
    "            \n",
    "    return pd.Series([found_correct_src, ranked_results, total_results])\n",
    "\n",
    "\n",
    "def compute_recall_rate_at_k(rank_array: pd.Series, k: int = 10):\n",
    "    correct_values = rank_array.loc[rank_array != -1]\n",
    "    return sum(correct_values < k) / len(rank_array)\n",
    "\n",
    "def get_query_statistics(result_df, col='total_results', rename_col='total_results'):\n",
    "    stat_df = pd.DataFrame(result_df[col].describe()) \n",
    "    stat_df.rename(columns={col: rename_col}, inplace=True)\n",
    "    return stat_df.T\n",
    "\n",
    "def generate_top_k_df(result_df, result_col, k_range=[1,5,10], op_label='operation'):\n",
    "    result_dict = {}\n",
    "    for k in [1,5,10]:\n",
    "        result_dict[f\"k={k}\"] = compute_recall_rate_at_k(result_df[result_col], k=k)\n",
    "    return pd.DataFrame(result_dict, index=[op_label])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tank/local/suhail/MATE/notebooks\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Total Query Results</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Ranking Rate @ k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>k=1</th>\n",
       "      <th>k=5</th>\n",
       "      <th>k=10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>groupby (2-col)</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1870.35</td>\n",
       "      <td>1442.200349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.75</td>\n",
       "      <td>1809.0</td>\n",
       "      <td>3368.0</td>\n",
       "      <td>3499.0</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Total Query Results                                     \\\n",
       "                              count     mean          std  min     25%   \n",
       "groupby (2-col)               100.0  1870.35  1442.200349  1.0  137.75   \n",
       "\n",
       "                                        Ranking Rate @ k              \n",
       "                    50%     75%     max              k=1   k=5  k=10  \n",
       "groupby (2-col)  1809.0  3368.0  3499.0             0.23  0.26  0.29  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_results = pd.read_parquet('../src/gb_results_2col_MATE.parquet')\n",
    "gb_results['src_filename'] = gb_results['src_labels'].apply(lambda x: os.path.basename(x[0]))\n",
    "gb_results[['correct_src_rank', 'ranked_results', 'total_results']] = gb_results.apply(verify_groupby_result_in_k, axis=1)\n",
    "groupby_qstats = get_query_statistics(gb_results, col='total_results', rename_col='groupby (2-col)')\n",
    "groupby_acc = generate_top_k_df(gb_results, result_col='correct_src_rank', op_label='groupby (2-col)')\n",
    "groupby_nums = pd.concat([groupby_qstats, groupby_acc], axis=1, keys=['Total Query Results', 'Ranking Rate @ k'])\n",
    "groupby_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Total Query Results</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Ranking Rate @ k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>k=1</th>\n",
       "      <th>k=5</th>\n",
       "      <th>k=10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pivot (2-col)</th>\n",
       "      <td>100.0</td>\n",
       "      <td>24.71</td>\n",
       "      <td>179.326028</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1795.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Total Query Results                                         \\\n",
       "                            count   mean         std  min  25%  50%  75%   \n",
       "pivot (2-col)               100.0  24.71  179.326028  1.0  1.0  1.0  8.0   \n",
       "\n",
       "                      Ranking Rate @ k              \n",
       "                  max              k=1   k=5  k=10  \n",
       "pivot (2-col)  1795.0              0.8  0.95  0.95  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_results = pd.read_parquet('../src/pivot_results_2col_MATE.parquet')\n",
    "pivot_results['src_filename'] = pivot_results['src_labels'].apply(lambda x: os.path.basename(x[0]))\n",
    "pivot_results[['correct_src_rank', 'ranked_results', 'total_results']] = pivot_results.apply(verify_pivot_result_in_k, axis=1)\n",
    "pivot_qstats = get_query_statistics(pivot_results, col='total_results', rename_col='pivot (2-col)')\n",
    "pivot_acc = generate_top_k_df(pivot_results, result_col='correct_src_rank', op_label='pivot (2-col)')\n",
    "pivot_nums = pd.concat([pivot_qstats, pivot_acc], axis=1, keys=['Total Query Results', 'Ranking Rate @ k'])\n",
    "pivot_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_labels</th>\n",
       "      <th>operation</th>\n",
       "      <th>args</th>\n",
       "      <th>dst_label</th>\n",
       "      <th>colset_size</th>\n",
       "      <th>results</th>\n",
       "      <th>src_filename</th>\n",
       "      <th>correct_src_rank</th>\n",
       "      <th>ranked_results</th>\n",
       "      <th>total_results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[J01-2004_11.parquet, W11-2123_aakansha_108.pa...</td>\n",
       "      <td>J01-2004_11.parquet</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dmsynth.dll.csv__3705671084__.parquet]</td>\n",
       "      <td>dmsynth.dll.csv__3705671084__.parquet</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[gameId=0041900235.parquet]</td>\n",
       "      <td>gameId=0041900235.parquet</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ConfigureExpandedStorage.dll.csv__2376278011_...</td>\n",
       "      <td>ConfigureExpandedStorage.dll.csv__2376278011__...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vm3dum64.dll.csv__17705870__.parquet]</td>\n",
       "      <td>vm3dum64.dll.csv__17705870__.parquet</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[NEON.D02.SCBI.DP1.10072.001.mam_perplotnight....</td>\n",
       "      <td>NEON.D02.SCBI.DP1.10072.001.mam_perplotnight.p...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tweets-@h3llatrash.parquet]</td>\n",
       "      <td>tweets-@h3llatrash.parquet</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ncobjapi.dll.csv__3645063681__.parquet]</td>\n",
       "      <td>ncobjapi.dll.csv__3645063681__.parquet</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Configuration3_window15_split12_typetest_proj...</td>\n",
       "      <td>Configuration3_window15_split9_typetest_projec...</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[E03-1005_186.parquet, E03-1005.annv3_83.parqu...</td>\n",
       "      <td>E03-1005.annv3_83.parquet</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            src_labels operation  \\\n",
       "300  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "301  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "302  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "303  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "304  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "..                                                 ...       ...   \n",
       "395  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "396  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "397  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "398  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "399  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "\n",
       "                                                  args  \\\n",
       "300  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "301  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "302  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "303  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "304  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "..                                                 ...   \n",
       "395  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "396  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "397  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "398  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "399  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "\n",
       "                                             dst_label  colset_size  \\\n",
       "300  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "301  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "302  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "303  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "304  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "..                                                 ...          ...   \n",
       "395  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "396  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "397  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "398  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "399  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "\n",
       "                                               results  \\\n",
       "300  [J01-2004_11.parquet, W11-2123_aakansha_108.pa...   \n",
       "301            [dmsynth.dll.csv__3705671084__.parquet]   \n",
       "302                        [gameId=0041900235.parquet]   \n",
       "303  [ConfigureExpandedStorage.dll.csv__2376278011_...   \n",
       "304             [vm3dum64.dll.csv__17705870__.parquet]   \n",
       "..                                                 ...   \n",
       "395  [NEON.D02.SCBI.DP1.10072.001.mam_perplotnight....   \n",
       "396                       [tweets-@h3llatrash.parquet]   \n",
       "397           [ncobjapi.dll.csv__3645063681__.parquet]   \n",
       "398  [Configuration3_window15_split12_typetest_proj...   \n",
       "399  [E03-1005_186.parquet, E03-1005.annv3_83.parqu...   \n",
       "\n",
       "                                          src_filename  correct_src_rank  \\\n",
       "300                                J01-2004_11.parquet                -1   \n",
       "301              dmsynth.dll.csv__3705671084__.parquet                -1   \n",
       "302                          gameId=0041900235.parquet                -1   \n",
       "303  ConfigureExpandedStorage.dll.csv__2376278011__...                -1   \n",
       "304               vm3dum64.dll.csv__17705870__.parquet                -1   \n",
       "..                                                 ...               ...   \n",
       "395  NEON.D02.SCBI.DP1.10072.001.mam_perplotnight.p...                -1   \n",
       "396                         tweets-@h3llatrash.parquet                -1   \n",
       "397             ncobjapi.dll.csv__3645063681__.parquet                -1   \n",
       "398  Configuration3_window15_split9_typetest_projec...                -1   \n",
       "399                          E03-1005.annv3_83.parquet                -1   \n",
       "\n",
       "     ranked_results  total_results  \n",
       "300               5              5  \n",
       "301               1              1  \n",
       "302               1              1  \n",
       "303               1              1  \n",
       "304               1              1  \n",
       "..              ...            ...  \n",
       "395               1              1  \n",
       "396               1              1  \n",
       "397               1              1  \n",
       "398              12             12  \n",
       "399               9              9  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">Total Query Results</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Ranking Rate @ k</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>k=1</th>\n",
       "      <th>k=5</th>\n",
       "      <th>k=10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>join (2-col)</th>\n",
       "      <td>100.0</td>\n",
       "      <td>1317.09</td>\n",
       "      <td>1459.74389</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.75</td>\n",
       "      <td>691.5</td>\n",
       "      <td>3011.0</td>\n",
       "      <td>3488.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Total Query Results                                         \\\n",
       "                           count     mean         std  min   25%    50%   \n",
       "join (2-col)               100.0  1317.09  1459.74389  1.0  4.75  691.5   \n",
       "\n",
       "                             Ranking Rate @ k              \n",
       "                 75%     max              k=1   k=5  k=10  \n",
       "join (2-col)  3011.0  3488.0             0.35  0.38  0.44  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Join Results\n",
    "\n",
    "\n",
    "def verify_join_column_in_original(ranking_keys, src_labels):\n",
    "    left_colset = set(x.replace('__LEFT', '') for x in ranking_keys if '__LEFT' in x)\n",
    "    right_colset = set(x.replace('__RIGHT', '') for x in ranking_keys if '__RIGHT' in x)\n",
    "                \n",
    "    #print(left_colset, right_colset)\n",
    "    join_src_mapping = {}\n",
    "    \n",
    "    for label in src_labels:\n",
    "        src_df = pd.read_parquet(label)\n",
    "        if set(src_df.columns).issuperset(left_colset):\n",
    "            join_src_mapping['left'] = os.path.basename(label)\n",
    "        if set(src_df.columns).issuperset(right_colset):\n",
    "            join_src_mapping['right'] = os.path.basename(label)\n",
    "    return join_src_mapping['left'], join_src_mapping['right']\n",
    "\n",
    "\n",
    "def verify_join_columns(row):\n",
    "    dst_cols = set(pd.read_parquet(row['dst_label']).columns)\n",
    "    return verify_join_column_in_original(dst_cols, row['src_labels'])\n",
    "\n",
    "\n",
    "def verify_join_result_in_k(row, k=10, side=0):\n",
    "    correct_src = verify_join_columns(row)[side]\n",
    "    found_correct_src = -1\n",
    "    ranked_results = 0\n",
    "    total_results = 0\n",
    "    \n",
    "    try:\n",
    "        total_results = len(row['results'][side])\n",
    "        \n",
    "        for ix, rank_item in enumerate(row['results'][side]):\n",
    "            if rank_item == correct_src and found_correct_src == -1:\n",
    "                found_correct_src = ranked_results\n",
    "            ranked_results += 1\n",
    "    except Exception as e:\n",
    "        #print(e)\n",
    "        pass\n",
    "            \n",
    "    return pd.Series([found_correct_src, ranked_results, total_results])\n",
    "    \n",
    "\n",
    "join_results = pd.read_parquet('../src/join_results_2col_MATE.parquet')\n",
    "join_results['src_filename'] = join_results['src_labels'].apply(lambda x: os.path.basename(x[0]))\n",
    "join_results[['correct_src_rank', 'ranked_results', 'total_results']] = join_results.apply(verify_join_result_in_k, axis=1)\n",
    "join_qstats = get_query_statistics(join_results, col='total_results', rename_col='join (2-col)')\n",
    "join_acc = generate_top_k_df(join_results, result_col='correct_src_rank', op_label='join (2-col)')\n",
    "join_nums = pd.concat([join_qstats, join_acc], axis=1, keys=['Total Query Results', 'Ranking Rate @ k'])\n",
    "join_nums\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'verify_join_result_in_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_17084/1947950051.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mjoin_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../src/join_results_2col_MATE.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mjoin_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_filename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'src_labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mjoin_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'correct_src_rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ranked_results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_results'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverify_join_result_in_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mjoin_qstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_query_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'total_results'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrename_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'join (2-col)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mjoin_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_top_k_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'correct_src_rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'join (2-col)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'verify_join_result_in_k' is not defined"
     ]
    }
   ],
   "source": [
    "join_results = pd.read_parquet('../src/join_results_2col_MATE.parquet')\n",
    "join_results['src_filename'] = join_results['src_labels'].apply(lambda x: os.path.basename(x[0]))\n",
    "join_results[['correct_src_rank', 'ranked_results', 'total_results']] = join_results.apply(verify_join_result_in_k, axis=1, side=1)\n",
    "join_qstats = get_query_statistics(join_results, col='total_results', rename_col='join (2-col)')\n",
    "join_acc = generate_top_k_df(join_results, result_col='correct_src_rank', op_label='join (2-col)')\n",
    "join_nums = pd.concat([join_qstats, join_acc], axis=1, keys=['Total Query Results', 'Ranking Rate @ k'])\n",
    "join_nums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Results (Why are pivots doing so well?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_labels</th>\n",
       "      <th>operation</th>\n",
       "      <th>args</th>\n",
       "      <th>dst_label</th>\n",
       "      <th>colset_size</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[J01-2004_11.parquet, W11-2123_aakansha_108.pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dmsynth.dll.csv__3705671084__.parquet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[gameId=0041900235.parquet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ConfigureExpandedStorage.dll.csv__2376278011_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vm3dum64.dll.csv__17705870__.parquet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[NEON.D02.SCBI.DP1.10072.001.mam_perplotnight....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tweets-@h3llatrash.parquet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ncobjapi.dll.csv__3645063681__.parquet]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Configuration3_window15_split12_typetest_proj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[E03-1005_186.parquet, E03-1005.annv3_83.parqu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            src_labels operation  \\\n",
       "300  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "301  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "302  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "303  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "304  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "..                                                 ...       ...   \n",
       "395  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "396  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "397  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "398  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "399  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "\n",
       "                                                  args  \\\n",
       "300  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "301  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "302  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "303  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "304  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "..                                                 ...   \n",
       "395  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "396  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "397  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "398  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "399  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "\n",
       "                                             dst_label  colset_size  \\\n",
       "300  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "301  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "302  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "303  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "304  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "..                                                 ...          ...   \n",
       "395  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "396  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "397  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "398  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "399  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "\n",
       "                                               results  \n",
       "300  [J01-2004_11.parquet, W11-2123_aakansha_108.pa...  \n",
       "301            [dmsynth.dll.csv__3705671084__.parquet]  \n",
       "302                        [gameId=0041900235.parquet]  \n",
       "303  [ConfigureExpandedStorage.dll.csv__2376278011_...  \n",
       "304             [vm3dum64.dll.csv__17705870__.parquet]  \n",
       "..                                                 ...  \n",
       "395  [NEON.D02.SCBI.DP1.10072.001.mam_perplotnight....  \n",
       "396                       [tweets-@h3llatrash.parquet]  \n",
       "397           [ncobjapi.dll.csv__3645063681__.parquet]  \n",
       "398  [Configuration3_window15_split12_typetest_proj...  \n",
       "399  [E03-1005_186.parquet, E03-1005.annv3_83.parqu...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect the key / group cardinality results\n",
    "pivot_results = pd.read_parquet('../src/pivot_results_2col_MATE.parquet')\n",
    "\n",
    "#join_results = pd.read_parquet('../src/join_results_2col_MATE.parquet')\n",
    "#join_results\n",
    "\n",
    "pivot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_labels</th>\n",
       "      <th>operation</th>\n",
       "      <th>args</th>\n",
       "      <th>dst_label</th>\n",
       "      <th>colset_size</th>\n",
       "      <th>results</th>\n",
       "      <th>query_cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[J01-2004_11.parquet, W11-2123_aakansha_108.pa...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dmsynth.dll.csv__3705671084__.parquet]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[gameId=0041900235.parquet]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ConfigureExpandedStorage.dll.csv__2376278011_...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vm3dum64.dll.csv__17705870__.parquet]</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[NEON.D02.SCBI.DP1.10072.001.mam_perplotnight....</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tweets-@h3llatrash.parquet]</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ncobjapi.dll.csv__3645063681__.parquet]</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Configuration3_window15_split12_typetest_proj...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[E03-1005_186.parquet, E03-1005.annv3_83.parqu...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            src_labels operation  \\\n",
       "300  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "301  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "302  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "303  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "304  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "..                                                 ...       ...   \n",
       "395  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "396  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "397  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "398  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "399  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "\n",
       "                                                  args  \\\n",
       "300  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "301  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "302  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "303  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "304  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "..                                                 ...   \n",
       "395  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "396  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "397  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "398  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "399  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "\n",
       "                                             dst_label  colset_size  \\\n",
       "300  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "301  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "302  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "303  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "304  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "..                                                 ...          ...   \n",
       "395  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "396  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "397  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "398  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "399  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "\n",
       "                                               results  query_cardinality  \n",
       "300  [J01-2004_11.parquet, W11-2123_aakansha_108.pa...                 17  \n",
       "301            [dmsynth.dll.csv__3705671084__.parquet]                 55  \n",
       "302                        [gameId=0041900235.parquet]                 17  \n",
       "303  [ConfigureExpandedStorage.dll.csv__2376278011_...                 96  \n",
       "304             [vm3dum64.dll.csv__17705870__.parquet]                104  \n",
       "..                                                 ...                ...  \n",
       "395  [NEON.D02.SCBI.DP1.10072.001.mam_perplotnight....                 99  \n",
       "396                       [tweets-@h3llatrash.parquet]                200  \n",
       "397           [ncobjapi.dll.csv__3645063681__.parquet]                 89  \n",
       "398  [Configuration3_window15_split12_typetest_proj...                256  \n",
       "399  [E03-1005_186.parquet, E03-1005.annv3_83.parqu...                 15  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_query_cardinality(row):\n",
    "    ''' Assumes df contains ICS first and the other column next'''\n",
    "    if row['operation'] == 'pivot':\n",
    "        col_filter = [row['args']['index_col'], row['args']['column_col']]\n",
    "    elif row['operation'] == 'join':\n",
    "        col_filter = [row['args']['key_col']]\n",
    "    elif row['operation'] == 'groupby':\n",
    "        col_filter = row['args']['colset']\n",
    "    \n",
    "    \n",
    "    df = pd.read_parquet(row['src_labels'][0])[col_filter]\n",
    "    return len(set(frozenset(x) for x in df.values.tolist()))#, {col: len(set(df[col].values)) for col in df.columns}\n",
    "\n",
    "\n",
    "pivot_results['query_cardinality'] = pivot_results.apply(get_query_cardinality, axis=1)\n",
    "pivot_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      68.260000\n",
       "std       76.883963\n",
       "min       10.000000\n",
       "25%       17.000000\n",
       "50%       28.000000\n",
       "75%       93.750000\n",
       "max      313.000000\n",
       "Name: query_cardinality, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_results.query_cardinality.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_labels</th>\n",
       "      <th>operation</th>\n",
       "      <th>args</th>\n",
       "      <th>dst_label</th>\n",
       "      <th>colset_size</th>\n",
       "      <th>results</th>\n",
       "      <th>query_cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[source_76.parquet, Future_Right2StepUpDown02...</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[PTN_20190923-191108.parquet], [source_76.par...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Maine_1.parquet, WD-WCAU45488665.parquet, no...</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Maine_1.parquet, WD-WCAU45488665.parquet, no...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Delaware.parquet, PL2331LAGM5SHJ.parquet, PL...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[A00-2018_sweta_21.parquet, E03-1005_sweta_10...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[Maine_1.parquet, WD-WCAU45488665.parquet, no...</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[8073.parquet], [Maine_1.parquet, WD-WCAU4548...</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[source_76.parquet, Future_Right2StepUpDown02...</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>join</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[[dua_lipa_scrape_59.parquet, lorde_scrape_47....</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           src_labels operation  \\\n",
       "0   [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "1   [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "2   [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "3   [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "4   [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "..                                                ...       ...   \n",
       "95  [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "96  [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "97  [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "98  [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "99  [/tank/local/suhail/data/relic-datalake/gittab...      join   \n",
       "\n",
       "                                                 args  \\\n",
       "0   {'agg_func': None, 'colset': None, 'column_col...   \n",
       "1   {'agg_func': None, 'colset': None, 'column_col...   \n",
       "2   {'agg_func': None, 'colset': None, 'column_col...   \n",
       "3   {'agg_func': None, 'colset': None, 'column_col...   \n",
       "4   {'agg_func': None, 'colset': None, 'column_col...   \n",
       "..                                                ...   \n",
       "95  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "96  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "97  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "98  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "99  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "\n",
       "                                            dst_label  colset_size  \\\n",
       "0   /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "1   /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "2   /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "3   /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "4   /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "..                                                ...          ...   \n",
       "95  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "96  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "97  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "98  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "99  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "\n",
       "                                              results  query_cardinality  \n",
       "0   [[source_76.parquet, Future_Right2StepUpDown02...                102  \n",
       "1   [[PTN_20190923-191108.parquet], [source_76.par...                 26  \n",
       "2   [[Maine_1.parquet, WD-WCAU45488665.parquet, no...                 20  \n",
       "3   [[Maine_1.parquet, WD-WCAU45488665.parquet, no...                 18  \n",
       "4   [[Delaware.parquet, PL2331LAGM5SHJ.parquet, PL...                 15  \n",
       "..                                                ...                ...  \n",
       "95  [[A00-2018_sweta_21.parquet, E03-1005_sweta_10...                 16  \n",
       "96  [[Maine_1.parquet, WD-WCAU45488665.parquet, no...                 23  \n",
       "97  [[8073.parquet], [Maine_1.parquet, WD-WCAU4548...                 26  \n",
       "98  [[source_76.parquet, Future_Right2StepUpDown02...                 16  \n",
       "99  [[dua_lipa_scrape_59.parquet, lorde_scrape_47....                 29  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_results['query_cardinality'] = join_results.apply(get_query_cardinality, axis=1)\n",
    "join_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby_results = pd.read_parquet('../src/gb_results_2col_MATE.parquet')\n",
    "groupby_results['query_cardinality'] = groupby_results.apply(get_query_cardinality, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      34.090000\n",
       "std       46.909346\n",
       "min       10.000000\n",
       "25%       16.000000\n",
       "50%       21.000000\n",
       "75%       34.250000\n",
       "max      395.000000\n",
       "Name: query_cardinality, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_results.query_cardinality.describe()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_labels</th>\n",
       "      <th>operation</th>\n",
       "      <th>args</th>\n",
       "      <th>dst_label</th>\n",
       "      <th>colset_size</th>\n",
       "      <th>results</th>\n",
       "      <th>query_cardinality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[J01-2004_11.parquet, W11-2123_aakansha_108.pa...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[dmsynth.dll.csv__3705671084__.parquet]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[gameId=0041900235.parquet]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ConfigureExpandedStorage.dll.csv__2376278011_...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[vm3dum64.dll.csv__17705870__.parquet]</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[NEON.D02.SCBI.DP1.10072.001.mam_perplotnight....</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tweets-@h3llatrash.parquet]</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[ncobjapi.dll.csv__3645063681__.parquet]</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[Configuration3_window15_split12_typetest_proj...</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>pivot</td>\n",
       "      <td>{'agg_func': None, 'colset': None, 'column_col...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[E03-1005_186.parquet, E03-1005.annv3_83.parqu...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            src_labels operation  \\\n",
       "300  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "301  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "302  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "303  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "304  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "..                                                 ...       ...   \n",
       "395  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "396  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "397  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "398  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "399  [/tank/local/suhail/data/relic-datalake/gittab...     pivot   \n",
       "\n",
       "                                                  args  \\\n",
       "300  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "301  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "302  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "303  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "304  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "..                                                 ...   \n",
       "395  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "396  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "397  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "398  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "399  {'agg_func': None, 'colset': None, 'column_col...   \n",
       "\n",
       "                                             dst_label  colset_size  \\\n",
       "300  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "301  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "302  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "303  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "304  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "..                                                 ...          ...   \n",
       "395  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "396  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "397  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "398  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "399  /tank/local/suhail/data/relic-datalake/gittabl...          NaN   \n",
       "\n",
       "                                               results  query_cardinality  \n",
       "300  [J01-2004_11.parquet, W11-2123_aakansha_108.pa...                 17  \n",
       "301            [dmsynth.dll.csv__3705671084__.parquet]                 55  \n",
       "302                        [gameId=0041900235.parquet]                 17  \n",
       "303  [ConfigureExpandedStorage.dll.csv__2376278011_...                 96  \n",
       "304             [vm3dum64.dll.csv__17705870__.parquet]                104  \n",
       "..                                                 ...                ...  \n",
       "395  [NEON.D02.SCBI.DP1.10072.001.mam_perplotnight....                 99  \n",
       "396                       [tweets-@h3llatrash.parquet]                200  \n",
       "397           [ncobjapi.dll.csv__3645063681__.parquet]                 89  \n",
       "398  [Configuration3_window15_split12_typetest_proj...                256  \n",
       "399  [E03-1005_186.parquet, E03-1005.annv3_83.parqu...                 15  \n",
       "\n",
       "[100 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pivot_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Reference Article', 14),\n",
       " ('From', 7),\n",
       " ('swda_filename', 5),\n",
       " ('type', 3),\n",
       " ('Title', 2),\n",
       " ('Namespace', 2),\n",
       " ('Citation Marker', 2),\n",
       " ('username', 2),\n",
       " ('Discourse Facet', 1),\n",
       " ('dmsynth.dll', 1),\n",
       " ('game_date', 1),\n",
       " ('2041-12-04T20:47:53.000Z', 1),\n",
       " ('2019-02-07T17:29:37.000Z', 1),\n",
       " ('38cf10ae098d1180db997f6ff2e9fd521c90a4c51d335d9975b1777ebe5548e6', 1),\n",
       " ('metric_type', 1),\n",
       " ('topic_description', 1),\n",
       " ('tua_uuid', 1),\n",
       " ('54003fe1c2f797c6ce3ed99f334f343a', 1),\n",
       " ('Editor', 1),\n",
       " ('b304b0ef47e125f696425bd99096d3e3', 1),\n",
       " ('ver', 1),\n",
       " ('ee3bd96db188b9703b17b2d6ed392633', 1),\n",
       " ('ID', 1),\n",
       " ('fms.dll', 1),\n",
       " ('Platform', 1),\n",
       " ('8c15c6e82cc790c71b09d4fbde7117b1d2a59d49a0604495eb969e9f1de30fc9', 1),\n",
       " ('cacls.exe', 1),\n",
       " ('week_end_date', 1),\n",
       " ('Native_Language', 1),\n",
       " ('game_id', 1),\n",
       " ('scrape_time', 1),\n",
       " ('Type', 1),\n",
       " ('FormulaConceptDB', 1),\n",
       " ('srds/srds87', 1),\n",
       " ('NORESP', 1),\n",
       " ('ProductID', 1),\n",
       " ('user_id', 1),\n",
       " ('clarityColor', 1),\n",
       " ('20811c49dc15a78945fedcd77d2bf6538d47b817e7caa2b46fa259825fc8635e', 1),\n",
       " ('State', 1),\n",
       " ('schema_sha256', 1),\n",
       " ('*', 1),\n",
       " ('city', 1),\n",
       " ('period', 1),\n",
       " ('2102-10-01T07:58:26.000Z', 1),\n",
       " ('1e96f651b8fababdb4c9814605d1aaac', 1),\n",
       " ('channelId', 1),\n",
       " ('Able to Test or Obtain Resources to Test All Current Residents Within Next 7 Days',\n",
       "  1),\n",
       " ('RPI Equiv id(s)', 1),\n",
       " ('Photo', 1),\n",
       " ('article_batch_name', 1),\n",
       " ('intent', 1),\n",
       " ('2069-12-24T00:30:06.000Z', 1),\n",
       " ('b5dd6e2406b354efac1721b8445ee82d', 1),\n",
       " ('9dff01594f11812292d9017983252246dbfc4d3a74fc1de341f200fd2b7aec82', 1),\n",
       " ('MutableTreeNode', 1),\n",
       " ('job_compared_name', 1),\n",
       " ('parent_id', 1),\n",
       " ('TenantId', 1),\n",
       " ('d5abc5ae6c9d13e56c9c08f466afe8a1e062a4cc8614e4edd979f18c2d9c3d77', 1),\n",
       " ('group_id:id', 1),\n",
       " ('Forum', 1),\n",
       " ('unUsefulGrouping', 1),\n",
       " ('chart_template_id:id', 1),\n",
       " ('ptb_basename', 1),\n",
       " ('portnumber', 1),\n",
       " ('Project', 1),\n",
       " ('aspnet_state.exe', 1),\n",
       " ('domainID', 1),\n",
       " ('ncobjapi.dll', 1),\n",
       " ('proj', 1)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "\n",
    "def count_col_types(df, arg_string):\n",
    "    counter = Counter()\n",
    "\n",
    "    for ix, row in df.iterrows():\n",
    "        counter[row['args'][arg_string]]= counter.get(row['args'][arg_string], 0) + 1\n",
    "        \n",
    "    return counter\n",
    "\n",
    "count_col_types(pivot_results, 'column_col').most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Unnamed: 0', 80),\n",
       " ('Citance Number', 6),\n",
       " ('Citation Text', 3),\n",
       " ('id', 2),\n",
       " ('date', 2),\n",
       " ('Line Number', 1),\n",
       " ('SELECTION_ID', 1),\n",
       " ('Message_id', 1),\n",
       " ('Name', 1),\n",
       " ('mag', 1),\n",
       " ('transcript_index', 1),\n",
       " ('answerid', 1)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_results = pd.read_parquet('../src/join_results_2col_MATE.parquet')\n",
    "count_col_types(join_results, 'key_col').most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('URL', 23),\n",
       " ('Comments', 23),\n",
       " ('Title', 22),\n",
       " ('Points', 20),\n",
       " ('Type', 19),\n",
       " ('act_tag', 5),\n",
       " ('Story', 4),\n",
       " ('speaker', 3),\n",
       " ('Namespace', 3),\n",
       " ('ce', 2),\n",
       " ('Unnamed: 0', 2),\n",
       " ('Table 5', 2),\n",
       " ('cbm', 2),\n",
       " ('genus', 2),\n",
       " ('File', 2),\n",
       " ('noc', 2),\n",
       " ('EVENT_NAME', 2),\n",
       " ('MORNINGTRADEDVOL', 2),\n",
       " ('topic_64', 1),\n",
       " ('sal5', 1),\n",
       " ('cbo', 1),\n",
       " ('End Date', 1),\n",
       " ('Location', 1),\n",
       " ('ObjectOriented Programming and Data Structures II', 1),\n",
       " ('predicted score', 1),\n",
       " ('LayerType', 1),\n",
       " ('RealTime(ms)', 1),\n",
       " ('HDPE', 1),\n",
       " ('O', 1),\n",
       " ('99%', 1),\n",
       " ('Win (1 of 2)', 1),\n",
       " ('ltable_year', 1),\n",
       " ('rtable_year', 1),\n",
       " ('in_iM', 1),\n",
       " ('category', 1),\n",
       " ('swda_filename', 1),\n",
       " ('Cause', 1),\n",
       " ('wmc', 1),\n",
       " ('max_cc', 1),\n",
       " ('Forum', 1),\n",
       " ('Author', 1),\n",
       " ('status', 1),\n",
       " ('ts', 1),\n",
       " ('subutterance_index', 1),\n",
       " ('Race Discipline', 1),\n",
       " ('Race Category', 1),\n",
       " ('topic_32', 1),\n",
       " ('0.1', 1),\n",
       " ('ca', 1),\n",
       " ('96%', 1),\n",
       " ('No win (2 of 5)', 1),\n",
       " ('LOC', 1),\n",
       " ('OREB_PCT', 1),\n",
       " ('DREB_PCT', 1),\n",
       " ('authors', 1),\n",
       " ('base_code_id/id', 1),\n",
       " ('ref_base_sign', 1),\n",
       " ('Class', 1),\n",
       " ('quantity', 1),\n",
       " ('frequency', 1),\n",
       " ('PC', 1),\n",
       " ('Distributor', 1),\n",
       " ('Estimated', 1),\n",
       " ('FXY2', 1),\n",
       " ('ElementDescription_en', 1),\n",
       " ('year', 1),\n",
       " ('Dew PointF', 1),\n",
       " ('Gust SpeedMPH', 1),\n",
       " ('chapter_id', 1),\n",
       " ('option4', 1),\n",
       " ('key', 1),\n",
       " ('type', 1),\n",
       " ('Citation Marker', 1),\n",
       " ('Reference Offset', 1),\n",
       " ('n_consonants', 1),\n",
       " ('n_consonantconjuncts', 1),\n",
       " ('junior', 1),\n",
       " ('5', 1)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_results = pd.read_parquet('../src/gb_results_2col_MATE.parquet')\n",
    "\n",
    "def count_gb_col_types(df, arg_string):\n",
    "    counter = Counter()\n",
    "\n",
    "    for ix, row in df.iterrows():\n",
    "        for col in row['args'][arg_string]:\n",
    "            counter[col]= counter.get(col, 0) + 1\n",
    "                    \n",
    "    return counter\n",
    "\n",
    "count_gb_col_types(groupby_results, 'colset').most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>521.795000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>468.990312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>102.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>192.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>319.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>698.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2658.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count   200.000000\n",
       "mean    521.795000\n",
       "std     468.990312\n",
       "min     102.000000\n",
       "25%     192.000000\n",
       "50%     319.000000\n",
       "75%     698.000000\n",
       "max    2658.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find token length distribution for the queries\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "\n",
    "\n",
    "def find_token_length(query_df, df_label='dst_label', query_col='colset'):\n",
    "    token_lengths = []\n",
    "    for ix, row in query_df.iterrows():\n",
    "        dst_col = row['args'][query_col]\n",
    "        dst_df = pd.read_parquet(row[df_label])\n",
    "        if type(dst_col) == set:\n",
    "            for col in dst_col:\n",
    "                token_lengths.extend(dst_df[col].apply(lambda x: len(str(x))).values.tolist())\n",
    "        else:\n",
    "            token_lengths.extend(dst_df[dst_col].apply(lambda x: len(str(x))).values.tolist())\n",
    "    return token_lengths\n",
    "    \n",
    "groupby_results = pd.read_parquet('../src/gb_results_2col_MATE.parquet')\n",
    "gb_tokens = find_token_length(groupby_results)\n",
    "pd.DataFrame(gb_tokens).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_labels</th>\n",
       "      <th>operation</th>\n",
       "      <th>args</th>\n",
       "      <th>dst_label</th>\n",
       "      <th>colset_size</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['Type', 'URL'],...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[07-08_1419.parquet, 08-09_1760.parquet, 07-08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['topic_64', 'sa...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[tokens_1838.parquet, tokens_37.parquet, token...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['Comments', 'UR...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[agreement_across_PP.parquet, Delaware.parquet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['Type', 'Points...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[23-24_714.parquet, 07-08_1419.parquet, 04-05_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['cbo', 'ce'], '...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[contradicting_6_nouns.parquet, agreement_acro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['n_consonants',...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[contradicting_6_nouns.parquet, agreement_acro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['Comments', 'Ti...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[agreement_across_PP.parquet, PL2331LAGM5SHJ.p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['Story', 'Comme...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[Delaware.parquet, PL2331LAGM5SHJ.parquet, PL2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['EVENT_NAME', '...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[dwbfpricesusaplace21102015.parquet, dwbfprice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>[/tank/local/suhail/data/relic-datalake/gittab...</td>\n",
       "      <td>groupby</td>\n",
       "      <td>{'agg_func': 'sum', 'colset': ['junior', '5'],...</td>\n",
       "      <td>/tank/local/suhail/data/relic-datalake/gittabl...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>[contradicting_6_nouns.parquet, agreement_acro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            src_labels operation  \\\n",
       "200  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "201  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "202  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "203  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "204  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "..                                                 ...       ...   \n",
       "295  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "296  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "297  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "298  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "299  [/tank/local/suhail/data/relic-datalake/gittab...   groupby   \n",
       "\n",
       "                                                  args  \\\n",
       "200  {'agg_func': 'sum', 'colset': ['Type', 'URL'],...   \n",
       "201  {'agg_func': 'sum', 'colset': ['topic_64', 'sa...   \n",
       "202  {'agg_func': 'sum', 'colset': ['Comments', 'UR...   \n",
       "203  {'agg_func': 'sum', 'colset': ['Type', 'Points...   \n",
       "204  {'agg_func': 'sum', 'colset': ['cbo', 'ce'], '...   \n",
       "..                                                 ...   \n",
       "295  {'agg_func': 'sum', 'colset': ['n_consonants',...   \n",
       "296  {'agg_func': 'sum', 'colset': ['Comments', 'Ti...   \n",
       "297  {'agg_func': 'sum', 'colset': ['Story', 'Comme...   \n",
       "298  {'agg_func': 'sum', 'colset': ['EVENT_NAME', '...   \n",
       "299  {'agg_func': 'sum', 'colset': ['junior', '5'],...   \n",
       "\n",
       "                                             dst_label  colset_size  \\\n",
       "200  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "201  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "202  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "203  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "204  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "..                                                 ...          ...   \n",
       "295  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "296  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "297  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "298  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "299  /tank/local/suhail/data/relic-datalake/gittabl...          2.0   \n",
       "\n",
       "                                               results  \n",
       "200  [07-08_1419.parquet, 08-09_1760.parquet, 07-08...  \n",
       "201  [tokens_1838.parquet, tokens_37.parquet, token...  \n",
       "202  [agreement_across_PP.parquet, Delaware.parquet...  \n",
       "203  [23-24_714.parquet, 07-08_1419.parquet, 04-05_...  \n",
       "204  [contradicting_6_nouns.parquet, agreement_acro...  \n",
       "..                                                 ...  \n",
       "295  [contradicting_6_nouns.parquet, agreement_acro...  \n",
       "296  [agreement_across_PP.parquet, PL2331LAGM5SHJ.p...  \n",
       "297  [Delaware.parquet, PL2331LAGM5SHJ.parquet, PL2...  \n",
       "298  [dwbfpricesusaplace21102015.parquet, dwbfprice...  \n",
       "299  [contradicting_6_nouns.parquet, agreement_acro...  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupby_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6826.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>38.551568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>139.383505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3693.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  6826.000000\n",
       "mean     38.551568\n",
       "std     139.383505\n",
       "min       1.000000\n",
       "25%       4.000000\n",
       "50%      16.000000\n",
       "75%      25.000000\n",
       "max    3693.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_src_token_length(query_df, df_label='src_df', query_col='colset'):\n",
    "    token_lengths = []\n",
    "    for ix, row in query_df.iterrows():\n",
    "        dst_col = row['args'][query_col]\n",
    "        dst_df = pd.read_parquet(row[df_label][0])\n",
    "        #print(dst_df.columns, dst_col)\n",
    "        if type(dst_col) == set:\n",
    "            for col in dst_col:\n",
    "                token_lengths.extend(dst_df[col].apply(lambda x: len(str(x))).values.tolist())\n",
    "        else:\n",
    "            token_lengths.extend(dst_df[dst_col].apply(lambda x: len(str(x))).values.tolist())\n",
    "    return token_lengths\n",
    "\n",
    "pivot_results = pd.read_parquet('../src/pivot_results_2col_MATE.parquet')\n",
    "pivot_tokens = find_src_token_length(pivot_results, df_label='src_labels', query_col='index_col')\n",
    "pd.DataFrame(pivot_tokens).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7576/1512118616.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpivot_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_parquet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../src/pivot_results_2col_MATE.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpivot_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_src_token_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'src_labels'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'index_col'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpivot_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pivot_results = pd.read_parquet('../src/pivot_results_2col_MATE.parquet')\n",
    "pivot_tokens = find_src_token_length(pivot_results, df_label='src_labels', query_col='index_col')\n",
    "pd.DataFrame(pivot_tokens).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4072.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.533644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.759938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>567.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "count  4072.000000\n",
       "mean      7.533644\n",
       "std      25.759938\n",
       "min       1.000000\n",
       "25%       2.000000\n",
       "50%       2.000000\n",
       "75%      10.000000\n",
       "max     567.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_results = pd.read_parquet('../src/join_results_2col_MATE.parquet')\n",
    "join_tokens = find_token_length(join_results, query_col='key_col')\n",
    "pd.DataFrame(join_tokens).describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d1a1c37ba461303326de108535748675a5b24d871b5510540e9cf6d9516fdf6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
